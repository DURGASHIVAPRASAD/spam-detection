{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "In this step, we load the data from the file. Each line in the file is a labeled sample that has this format:\n",
    "\n",
    "*{spam_or_ham},{email_text}*\n",
    "\n",
    "The first part is the label that identifies whether the email is spam or ham (not spam), followed by the email text. For example:\n",
    "\n",
    "`Spam,<p>But few feere in nor revellers in pride the a. Ear fathers yes begun revellers blazon one but not of take high. In had his her satiety alone fulness he sins perchance in thence climes nine scorching weary drugged...`\n",
    "\n",
    "We will load all the sample into two lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no. of samples: 2100\n",
      "total no. of spam samples: 1043\n",
      "total no. of ham samples: 1057\n",
      "\n",
      "Print a random sample for inspection:\n",
      "example feature: <p>Mood for thence sorrow the before and me are love suffice festal as suits. Harolds not care rill tis ways ah to. They bliss and to he below bade left. Mine none none from worse worse but these but was ye neer whateer. Loved and nor. Along him shamed and nor aisle strength he adversity his monks loved his power was companie. All pollution hall was was riot in true been will ever his so. That at of perchance to and would was degree clay pleasure hope few. Oh all there was would eremites. Dwelt for plain whence earthly a feere by den for go seraphs youth day. And only change visit nine for however tear albions sick breast he say to feere degree it save. Deemed call light minstrels break men her superstition but flee muse mine yes bade nine though her grace oft. Feeble but he feel holy name in save. Grief reverie not of spent he feere crime his shades light but not brow heavenly a nor. Known childe aye sad there for soul he left lay ever deemed counsel wrong and which to known. Coffined before since. Fathers finds nor shameless like mirth. His his blazon noontide mine. From eremites to of longdeserted and kiss he amiss rhyme near things.</p><p>Tis call not most tis. Than condemned flee and but glare nor misery revel break later for den despair and adversity flee tales his. Visit could of longed to sadness saw thou shameless way pomp a him nine carnal. Eros of friends his neer ne fathers loved aye of at wandered not a from third he a land. Kiss if to ah a flow his rake and a and beyond strange suffice gild nor to lyres prose. Flatterers relief was before for feere yet within native harold. Awake mirthful were childe before are. Not girls pilgrimage into can seemed name if but some days. Seek his to but his if hall it what awake the was seraphs not in wandered. Her harolds reverie revellers a bower was from nor and had dwelt would would nor he reverie. Ere dwelt condole in far nor name times and he childe his made nor shameless all womans heavenly. Deemed a mote the made in his to from alas stalked run. But brow consecrate had my his. Fame native if and smile it yet and low yet unto smile disporting present he to the for. Soon his uses below so woe would still mine. From it the gild isle long to pile had was of for than charms to upon like talethis. Which a earth and mirthful parting deeds longed he. To mirth with adieu are cared or soon companie was ever mine had. Save sight feere suits his things ne mood neer true sun counsel amiss by lines sea gathered.</p>\n",
      "example label: 1 (spam)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def read_file(path):\n",
    "    \"\"\"\n",
    "    read and return all data in a file\n",
    "    \"\"\"\n",
    "    with open(path, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    load and return the data in features and labels lists\n",
    "    each item in features contains the raw email text\n",
    "    each item in labels identifies whether the corresponding item in features is spam (1) or ham (0)\n",
    "    \"\"\"\n",
    "    # load all data from file\n",
    "    data_path = \"data/SpamDetectionData.txt\"\n",
    "    all_data = read_file(data_path)\n",
    "    \n",
    "    # split the data into lines, each line is a single sample\n",
    "    all_lines = all_data.split('\\n')\n",
    "\n",
    "    # each line in the file is a sample and has the following format\n",
    "    # it begins with either \"Spam,\" or \"Ham,\", and follows by the actual text of the email\n",
    "    # e.g. Spam,<p>His honeyed and land....\n",
    "    \n",
    "    # extract the feature (email text) and label (spam or ham) from each line\n",
    "    features = []\n",
    "    labels = []\n",
    "    for line in all_lines:\n",
    "        if line[0:4] == 'Spam':\n",
    "            labels.append(1)\n",
    "            features.append(line[5:])\n",
    "            pass\n",
    "        elif line[0:3] == 'Ham':\n",
    "            labels.append(0)\n",
    "            features.append(line[4:])\n",
    "            pass\n",
    "        else:\n",
    "            # ignore markers, empty lines and other lines that aren't valid sample\n",
    "            # print('ignore: \"{}\"'.format(line));\n",
    "            pass\n",
    "    \n",
    "    return features, labels\n",
    "    \n",
    "features, labels = load_data()\n",
    "\n",
    "print(\"total no. of samples: {}\".format(len(labels)))\n",
    "print(\"total no. of spam samples: {}\".format(labels.count(1)))\n",
    "print(\"total no. of ham samples: {}\".format(labels.count(0)))\n",
    "\n",
    "print(\"\\nPrint a random sample for inspection:\")\n",
    "random_sample = random.randint(0, len(labels))\n",
    "print(\"example feature: {}\".format(features[random_sample][0:]))\n",
    "print(\"example label: {} ({})\".format(labels[random_sample], 'spam' if labels[random_sample] else 'ham'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of train features: 1890\n",
      "no. of train labels: 1890\n",
      "no. of test features: 210\n",
      "no. of test labels: 210\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# load features and labels\n",
    "features, labels = load_data()\n",
    "\n",
    "# split data into training / test sets\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(\n",
    "    features, \n",
    "    labels, \n",
    "    test_size=0.1,   # use 10% for testing\n",
    "    random_state=42)\n",
    "\n",
    "print(\"no. of train features: {}\".format(len(features_train)))\n",
    "print(\"no. of train labels: {}\".format(len(labels_train)))\n",
    "print(\"no. of test features: {}\".format(len(features_test)))\n",
    "print(\"no. of test labels: {}\".format(len(labels_test)))\n",
    "\n",
    "# vectorize email text into tfidf matrix\n",
    "# TfidfVectorizer converts collection of raw documents to a matrix of TF-IDF features.\n",
    "# It's equivalent to CountVectorizer followed by TfidfTransformer.\n",
    "vectorizer = TfidfVectorizer(\n",
    "    input='content',     # input is actual text\n",
    "    lowercase=True,      # convert to lower case before tokenizing\n",
    "    stop_words='english' # remove stop words\n",
    ")\n",
    "features_train_transformed = vectorizer.fit_transform(features_train)\n",
    "features_test_transformed  = vectorizer.transform(features_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle\n",
    "\n",
    "def save(vectorizer, clf):\n",
    "    '''\n",
    "    save classifier from disk\n",
    "    '''\n",
    "    with open('clf.pkl', 'wb') as file:\n",
    "        pickle.dump((vectorizer, clf), file)\n",
    "        \n",
    "def load():\n",
    "    '''\n",
    "    load classifier from disk\n",
    "    '''\n",
    "    with open('clf.pkl', 'rb') as file:\n",
    "      vectorizer, clf = pickle.load(file)\n",
    "    return vectorizer, clf\n",
    "\n",
    "# train a classifier\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(features_train_transformed, labels_train)\n",
    "\n",
    "# save classifier\n",
    "save(vectorizer, classifier)\n",
    "\n",
    "# score the classifier accuracy\n",
    "print(\"classifier accuracy {:.2f}%\".format(classifier.score(features_test_transformed, labels_test) * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perform a test\n",
      "spam\n"
     ]
    }
   ],
   "source": [
    "saved_classifer = load()\n",
    "\n",
    "print('\\nPerform a test')                    \n",
    "test_case = ['is this a spam letter? what are some of the spammy letters? nd long power goodly had formed pilgrimage and domestic longdeserted revellers than so and to. Heartless in other reverie dome birth land the did sad more bidding not by childe the. To from maidens the seraphs haply hall passion losel pillared the monks that be his his true have. Stalked open all now parasites day their true it revel apart who and. One had haply was lineage if which in and cell loathed him pomp from hall ever to and oer. Nor sore disporting grief call sad long by feel scorching ofttimes things. Tales his was drowsy visit her by and himnot he deem blazon lyres for pillared. His childe disporting labyrinth honeyed mirthful']\n",
    "test_case_transformed = vectorizer.transform(test_case)\n",
    "prediction = clf.predict(test_case_transformed)\n",
    "print('spam' if prediction else 'ham')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
